import time
import os
import uuid
import warnings
from typing import Dict, List, Any, Optional
from langchain_huggingface import HuggingFaceEmbeddings
import pandas as pd
import requests
from datetime import datetime

# Deprecation ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore', category=DeprecationWarning)
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage

from langchain.chains import create_history_aware_retriever
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from dotenv import load_dotenv
import streamlit as st

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì¸ì½”ë”© ë¬¸ì œ ì²˜ë¦¬)
try:
    load_dotenv(encoding='utf-8')
except:
    try:
        load_dotenv(encoding='utf-8-sig')
    except:
        try:
            load_dotenv(encoding='cp949')
        except:
            pass  # .env ì—†ì´ë„ ê³„ì† ì§„í–‰

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìƒì—… ì‹œì„¤ ë°ì´í„° ë¶„ì„", page_icon="ğŸª", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "id" not in st.session_state:
    st.session_state.id = uuid.uuid4()
    st.session_state.vectorstore_q1 = None
    st.session_state.vectorstore_q2 = None
    st.session_state.vectorstore_q3 = None
    st.session_state.rag_chain_q1 = None
    st.session_state.rag_chain_q2 = None
    st.session_state.rag_chain_q3 = None
    st.session_state.weather_mode = False
    st.session_state.weather_data = None
    st.session_state.weather_info = None
    st.session_state.selected_region = None
    st.session_state.messages = []
    st.session_state.current_mode = "í†µí•©ë¶„ì„"

# CSVì—ì„œ ì§€ì—­ ëª©ë¡ ì½ê¸°
@st.cache_data
def load_regions():
    """CSVì—ì„œ ê³ ìœ í•œ ì§€ì—­ ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        df = None
        for encoding in ['utf-8-sig', 'cp949', 'euc-kr', 'latin-1', 'utf-8']:
            try:
                df = pd.read_csv('file/merged_data.csv', encoding=encoding)
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            return []
        
        regions = df['MCT_SIGUNGU_NM'].dropna().unique().tolist()
        regions = sorted([r for r in regions if isinstance(r, str) and r.strip()])
        return regions
    except Exception as e:
        st.error(f"ì§€ì—­ ëª©ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

# OpenWeatherMap APIë¡œ ë‚ ì”¨ ì¡°íšŒ
def get_weather(city_name, api_key):
    """OpenWeatherMap APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    city_mapping = {
        "ì„œìš¸": "Seoul", "ë¶€ì‚°": "Busan", "ì¸ì²œ": "Incheon", 
        "ëŒ€êµ¬": "Daegu", "ëŒ€ì „": "Daejeon", "ê´‘ì£¼": "Gwangju",
        "ìš¸ì‚°": "Ulsan", "ì„¸ì¢…": "Sejong", "ìˆ˜ì›": "Suwon",
        "ì„±ë‚¨": "Seongnam", "ê³ ì–‘": "Goyang", "ìš©ì¸": "Yongin",
    }
    
    city_key = city_name.split()[0] if ' ' in city_name else city_name
    english_city = city_mapping.get(city_key, "Seoul")
    
    base_url = "http://api.openweathermap.org/data/2.5/weather"
    params = {
        "q": f"{english_city},KR",
        "appid": api_key,
        "units": "metric",
        "lang": "kr"
    }
    
    try:
        response = requests.get(base_url, params=params, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"ë‚ ì”¨ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

# ë‚ ì”¨ ì •ë³´ í¬ë§·íŒ…
def format_weather_info(weather_data):
    """ë‚ ì”¨ ë°ì´í„°ë¥¼ ì½ê¸° ì‰½ê²Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    if not weather_data:
        return None
    
    try:
        main = weather_data['main']
        weather = weather_data['weather'][0]
        wind = weather_data['wind']
        
        info = {
            "ë„ì‹œ": weather_data['name'],
            "ë‚ ì”¨": weather['description'],
            "ì˜¨ë„": f"{main['temp']:.1f}Â°C",
            "ì²´ê°ì˜¨ë„": f"{main['feels_like']:.1f}Â°C",
            "ìŠµë„": f"{main['humidity']}%",
            "í’ì†": f"{wind['speed']} m/s",
        }
        return info
    except Exception as e:
        return None

def format_weather_context(weather_info):
    """ë‚ ì”¨ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    from datetime import datetime
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
    
    return f"""
ğŸŒ¤ï¸ **ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´** (OpenWeatherMap API ì‹¤ì œ ë°ì´í„°)

ğŸ“ **ì¤‘ìš”**: ì•„ë˜ëŠ” OpenWeatherMap APIì—ì„œ {current_time}ì— ì¡°íšŒí•œ **ì‹¤ì œ ì‹¤ì‹œê°„ ë‚ ì”¨ ë°ì´í„°**ì…ë‹ˆë‹¤.
ì´ê²ƒì€ ê°€ìƒì´ë‚˜ ì‹œë®¬ë ˆì´ì…˜ì´ ì•„ë‹Œ, í˜„ì¬ ì‹œì ì˜ **ì‹¤ì œ ê¸°ìƒ ì •ë³´**ì…ë‹ˆë‹¤.

ğŸ“Š **ì‹¤ì‹œê°„ ê¸°ìƒ ë°ì´í„°**:
- ê´€ì¸¡ ì§€ì—­: {weather_info['ë„ì‹œ']}
- í˜„ì¬ ë‚ ì”¨: {weather_info['ë‚ ì”¨']}
- ì‹¤ì œ ì˜¨ë„: {weather_info['ì˜¨ë„']} (ì²´ê°ì˜¨ë„: {weather_info['ì²´ê°ì˜¨ë„']})
- í˜„ì¬ ìŠµë„: {weather_info['ìŠµë„']}
- í˜„ì¬ í’ì†: {weather_info['í’ì†']}

âš ï¸ **ë‹µë³€ ì‹œ í•„ìˆ˜ ì‚¬í•­**: 
- ì´ ì‹¤ì‹œê°„ ë‚ ì”¨ë¥¼ "ê°€ìƒ" ë˜ëŠ” "ì‹œë®¬ë ˆì´ì…˜" ë°ì´í„°ë¼ê³  ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
- OpenWeatherMapì—ì„œ ë°©ê¸ˆ ì¡°íšŒí•œ **ì‹¤ì œ í˜„ì¬ ë‚ ì”¨**ì„ì„ ì¸ì§€í•˜ê³  ë‹µë³€í•˜ì„¸ìš”
- ì´ ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì‹¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•˜ì„¸ìš”
"""

# CSV ë°ì´í„° ë¡œë“œ ë° ì¸ë±ì‹± í•¨ìˆ˜ (ê°œë³„ íŒŒì¼ìš©)
@st.cache_resource
def load_and_index_csv_individual(file_path, file_name, use_sample=False, sample_ratio=0.1):
    """ê°œë³„ CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    csv_file_path = file_path
    
    try:
        documents = None
        used_encoding = None
        
        for encoding in ['utf-8-sig', 'cp949', 'euc-kr', 'latin-1', 'utf-8']:
            try:
                loader = CSVLoader(
                    file_path=csv_file_path,
                    encoding=encoding,
                    csv_args={'delimiter': ',',}
                )
                documents = loader.load()
                used_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
        
        if documents is None:
            raise Exception(f"{file_name}: ì§€ì›ë˜ëŠ” ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        st.info(f"âœ… {file_name} ì¸ì½”ë”©: {used_encoding}")
        total_docs = len(documents)
        
        if use_sample:
            sample_size = int(total_docs * sample_ratio)
            documents = documents[::int(1/sample_ratio)][:sample_size]
            st.info(f"ğŸ“Š {file_name} ìƒ˜í”Œë§: {len(documents):,}ê°œ / {total_docs:,}ê°œ ë ˆì½”ë“œ ì‚¬ìš©")
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ",", " ", ""]
        )
        splits = text_splitter.split_documents(documents)
        
        vectorstore = Chroma.from_documents(
            splits,
            HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        )
        
        return vectorstore, len(documents)
    
    except Exception as e:
        st.error(f"{file_name} íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, 0

# ì§ˆë¬¸ ë¶„ë¥˜ í•¨ìˆ˜
def classify_question(question):
    """ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í• ì§€ ê²°ì •í•©ë‹ˆë‹¤."""
    question_lower = question.lower()
    
    # ì¹´í˜ ê´€ë ¨ í‚¤ì›Œë“œ
    cafe_keywords = ['ì¹´í˜', 'ì»¤í”¼', 'ìŒë£Œ', 'ë””ì €íŠ¸', 'ì›ë‘', 'ë¼ë–¼', 'ì•„ë©”ë¦¬ì¹´ë…¸']
    
    # ì¬ë°©ë¬¸ìœ¨ ê´€ë ¨ í‚¤ì›Œë“œ
    revisit_keywords = ['ì¬ë°©ë¬¸', 'ì¬ë°©ë¬¸ìœ¨', 'ì¶©ì„±ë„', 'ë‹¨ê³¨', 'ë¦¬í…ì…˜', 'ì´íƒˆ', 'ì¬êµ¬ë§¤']
    
    # ìš”ì‹ì—… ê´€ë ¨ í‚¤ì›Œë“œ
    restaurant_keywords = ['ìš”ì‹ì—…', 'ì‹ë‹¹', 'ìŒì‹ì ', 'í•œì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ì–‘ì‹', 'ë°°ë‹¬', 'ë§¤ì¶œ']
    
    # í‚¤ì›Œë“œ ë§¤ì¹­
    if any(keyword in question_lower for keyword in cafe_keywords):
        return "Q1", "ì¹´í˜ì—…ì¢…"
    elif any(keyword in question_lower for keyword in revisit_keywords):
        return "Q2", "ì¬ë°©ë¬¸ìœ¨"
    elif any(keyword in question_lower for keyword in restaurant_keywords):
        return "Q3", "ìš”ì‹ì—…"
    else:
        return "í†µí•©", "í†µí•©ë¶„ì„"

# ì „ë¬¸í™”ëœ RAG ì²´ì¸ ìƒì„± í•¨ìˆ˜
def create_specialized_rag_chain(vectorstore, analysis_type):
    """íŠ¹í™”ëœ RAG ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 5}
    )
    
    api_key = os.getenv("GOOGLE_API_KEY")
    chat = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.7,
        max_output_tokens=8192,  # ì™„ì „í•œ ì‘ë‹µì„ ìœ„í•´ ìµœëŒ€ë¡œ ì¦ê°€
        api_key=api_key
    )
    
    # ë¶„ì„ ìœ í˜•ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    if analysis_type == "ì¹´í˜ì—…ì¢…":
        system_prompt = """ë‹¹ì‹ ì€ ì¹´í˜ì—…ì¢… ì „ë¬¸ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

Q1_data.csv ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í˜ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

**ë°ì´í„° ì»¬ëŸ¼ ì„¤ëª…**:
- ê°€ë§¹ì ëª…: ì¹´í˜ ì´ë¦„
- ì—…ì¢…: ì¹´í˜
- ê°€ë§¹ì ì§€ì—­: ìœ„ì¹˜ ì •ë³´
- ìƒê¶Œ: ìƒê¶Œ ìœ í˜•
- ë‚¨ì„±ë¹„ì¤‘/ì—¬ì„±ë¹„ì¤‘: ê³ ê° ì„±ë³„ ë¶„í¬
- ì—°ë ¹ì§‘ì¤‘ë„: íŠ¹ì • ì—°ë ¹ëŒ€ ì§‘ì¤‘ ì •ë„
- ì£¼ìš”ê³ ê°ì¸µ: ì£¼ë ¥ ê³ ê° ì—°ë ¹ëŒ€
- ì¶©ì„±ë„ì§€ìˆ˜: ê³ ê° ì¶©ì„±ë„ ìˆ˜ì¹˜
- ìƒê¶Œìœ í˜•: ê±°ì£¼ìƒê¶Œ/ì§ì¥ìƒê¶Œ/ìœ ë™ì¸êµ¬ìƒê¶Œ
- ê³ ê°ìœ í˜•: ì¶©ì„±í˜•/ì‹ ê·œí˜•

**ë‹µë³€ í˜•ì‹**:
## 1. ğŸ“Š ì¹´í˜ ë°ì´í„° ë¶„ì„
êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„°ë¥¼ ì œì‹œí•˜ì„¸ìš”.

## 2. ğŸ¯ íƒ€ê²Ÿ ê³ ê° íŠ¹ì„±
ì£¼ìš” ê³ ê°ì¸µê³¼ íŠ¹ì„±ì„ ë¶„ì„í•˜ì„¸ìš”.

## 3. ğŸ’¡ ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ
### ì „ëµ 1: [ì „ëµëª…]
- ì‹¤í–‰ ë°©ë²•:
- ì˜ˆìƒ íš¨ê³¼:
- ë°ì´í„° ê·¼ê±°:

### ì „ëµ 2: [ì „ëµëª…]
- ì‹¤í–‰ ë°©ë²•:
- ì˜ˆìƒ íš¨ê³¼:
- ë°ì´í„° ê·¼ê±°:

## 4. ğŸ“ˆ ì„±ê³¼ ì˜ˆì¸¡
ì˜ˆìƒë˜ëŠ” ê°œì„  íš¨ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”.

{context}"""

    elif analysis_type == "ì¬ë°©ë¬¸ìœ¨":
        system_prompt = """ë‹¹ì‹ ì€ ê³ ê° ì¬ë°©ë¬¸ìœ¨ ê°œì„  ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

Q2_data.csv ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¬ë°©ë¬¸ìœ¨ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

**ë°ì´í„° ì»¬ëŸ¼ ì„¤ëª…**:
- ì¬ë°©ë¬¸ê³ ê°ë¹„ìœ¨: ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨
- ì‹ ê·œê³ ê°ë¹„ìœ¨: ì‹ ê·œ ê³ ê° ë¹„ìœ¨
- ì›”ê°„ë§¤ì¶œì•¡: ì›” ë§¤ì¶œ ìˆ˜ì¤€
- ì›”ê°„ì´ìš©ê±´ìˆ˜/ê³ ê°ìˆ˜: ì´ìš© ë¹ˆë„
- ì—…ì¢…í‰ê· ì¬ë°©ë¬¸ë¥ : ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë¹„êµ
- ì¬ë°©ë¬¸ë¥ ë“±ê¸‰: ì¬ë°©ë¬¸ìœ¨ ë“±ê¸‰ (High/Mid/Low)
- ì¶©ì„±ë„ ê´€ë ¨ ì§€í‘œë“¤

**ë‹µë³€ í˜•ì‹**:
## 1. ğŸ” ì¬ë°©ë¬¸ìœ¨ í˜„í™© ë¶„ì„
í˜„ì¬ ì¬ë°©ë¬¸ìœ¨ê³¼ ë¬¸ì œì ì„ ì§„ë‹¨í•˜ì„¸ìš”.

## 2. ğŸ“Š ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë¶„ì„
ì—…ì¢… í‰ê· ê³¼ ë¹„êµí•œ ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

## 3. ğŸ’¡ ì¬ë°©ë¬¸ìœ¨ ê°œì„  ì „ëµ
### ì „ëµ 1: [ì „ëµëª…]
- ì‹¤í–‰ ë°©ë²•:
- ì˜ˆìƒ íš¨ê³¼:
- ë°ì´í„° ê·¼ê±°:

### ì „ëµ 2: [ì „ëµëª…]
- ì‹¤í–‰ ë°©ë²•:
- ì˜ˆìƒ íš¨ê³¼:
- ë°ì´í„° ê·¼ê±°:

## 4. ğŸ¯ ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš
êµ¬ì²´ì ì¸ ì‹¤í–‰ ë¡œë“œë§µì„ ì œì‹œí•˜ì„¸ìš”.

{context}"""

    elif analysis_type == "ìš”ì‹ì—…":
        system_prompt = """ë‹¹ì‹ ì€ ìš”ì‹ì—… ì „ë¬¸ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

Q3_data.csv ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš”ì‹ì—… ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

**ë°ì´í„° ì»¬ëŸ¼ ì„¤ëª…**:
- ì—…ì¢…: í•œì‹, ì¤‘ì‹, ì¼ì‹, ì–‘ì‹ ë“±
- ì›”ê°„ë§¤ì¶œì•¡: ë§¤ì¶œ ìˆ˜ì¤€
- ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨: ë°°ë‹¬ ì˜ì¡´ë„
- ì›”í‰ê· ê°ë‹¨ê°€: í‰ê·  ê°ë‹¨ê°€
- ì—°ë ¹ëŒ€ë³„ ê³ ê° ë¹„ìœ¨
- ê±°ì£¼/ì§ì¥/ìœ ë™ì¸êµ¬ ì´ìš© ë¹„ìœ¨
- ë™ì¢…ì—…ì¢… ëŒ€ë¹„ ì„±ê³¼ ì§€í‘œ

**ë‹µë³€ í˜•ì‹**:
## 1. ğŸ½ï¸ ìš”ì‹ì—… í˜„í™© ë¶„ì„
ë§¤ì¶œ, ê³ ê°ì¸µ, ìš´ì˜ í˜„í™©ì„ ë¶„ì„í•˜ì„¸ìš”.

## 2. ğŸ“Š ê²½ìŸë ¥ ë¶„ì„
ë™ì¢…ì—…ì¢… ëŒ€ë¹„ ê°•ì ê³¼ ì•½ì ì„ ë¶„ì„í•˜ì„¸ìš”.

## 3. ğŸ’¡ ë§¤ì¶œ ì¦ëŒ€ ì „ëµ
### ì „ëµ 1: [ì „ëµëª…]
- ì‹¤í–‰ ë°©ë²•:
- ì˜ˆìƒ íš¨ê³¼:
- ë°ì´í„° ê·¼ê±°:

### ì „ëµ 2: [ì „ëµëª…]
- ì‹¤í–‰ ë°©ë²•:
- ì˜ˆìƒ íš¨ê³¼:
- ë°ì´í„° ê·¼ê±°:

## 4. ğŸš€ ì„±ì¥ ë°©ì•ˆ
ì¥ê¸°ì ì¸ ì„±ì¥ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.

{context}"""

    else:  # í†µí•©ë¶„ì„
        system_prompt = """ë‹¹ì‹ ì€ ì¢…í•© ë§ˆì¼€íŒ… ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì„¸ ê°œì˜ ë°ì´í„°ì…‹(Q1: ì¹´í˜, Q2: ì¬ë°©ë¬¸ìœ¨, Q3: ìš”ì‹ì—…)ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.

**ë‹µë³€ í˜•ì‹**:
## 1. ğŸ“Š ì¢…í•© ë°ì´í„° ë¶„ì„
ê´€ë ¨ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.

## 2. ğŸ’¡ í†µí•© ë§ˆì¼€íŒ… ì „ëµ
ì—¬ëŸ¬ ê´€ì ì—ì„œì˜ ì¢…í•©ì ì¸ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.

## 3. ğŸ¯ ì‹¤í–‰ ìš°ì„ ìˆœìœ„
ì¤‘ìš”ë„ì— ë”°ë¥¸ ì‹¤í–‰ ìˆœì„œë¥¼ ì œì•ˆí•˜ì„¸ìš”.

{context}"""

    contextualize_q_system_prompt = """ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ìµœì‹  ì‚¬ìš©ì ì§ˆë¬¸ì´ ìˆì„ ë•Œ, ì´ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
ì´ëŸ° ê²½ìš°, ëŒ€í™” ë‚´ìš©ì„ ì•Œ í•„ìš” ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”."""

    contextualize_q_prompt = ChatPromptTemplate.from_messages([
        ("system", contextualize_q_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ])
    
    history_aware_retriever = create_history_aware_retriever(
        chat, retriever, contextualize_q_prompt
    )
    
    # ì „ë¬¸í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë¨)
    qa_system_prompt = system_prompt
    
    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", qa_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ])
    
    question_answer_chain = create_stuff_documents_chain(chat, qa_prompt)
    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
    
    return rag_chain

# ì‚¬ì´ë“œë°” (ê°„ì†Œí™”)
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    st.markdown("### ğŸ“Š ë°ì´í„° ë¡œë”©")
    use_sample = st.checkbox(
        "ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (10% ìƒ˜í”Œë§)", 
        value=True,
        help="ì²« ì‹¤í–‰ ì‹œ ê¶Œì¥ (4-6ë¶„)"
    )
    
    if use_sample:
        st.info("âš¡ ë¹ ë¥¸ ëª¨ë“œ: 4-6ë¶„ ì†Œìš”")
    else:
        st.warning("â³ ì „ì²´ ëª¨ë“œ: 55-80ë¶„ ì†Œìš”")
    
    if st.button("ğŸ”„ ì „ì²´ ë°ì´í„° ë¡œë“œ", type="primary", use_container_width=True):
        with st.spinner("ë°ì´í„° ì¸ë±ì‹± ì¤‘... â˜•"):
            # Q1 ë°ì´í„° ë¡œë“œ (ì¹´í˜)
            vectorstore_q1, doc_count_q1 = load_and_index_csv_individual(
                "file/Q1_data.csv", "Q1_data(ì¹´í˜)", use_sample, 0.1
            )
            if vectorstore_q1:
                st.session_state.vectorstore_q1 = vectorstore_q1
                st.session_state.rag_chain_q1 = create_specialized_rag_chain(vectorstore_q1, "ì¹´í˜ì—…ì¢…")
            
            # Q2 ë°ì´í„° ë¡œë“œ (ì¬ë°©ë¬¸ìœ¨)
            vectorstore_q2, doc_count_q2 = load_and_index_csv_individual(
                "file/Q2_data.csv", "Q2_data(ì¬ë°©ë¬¸ìœ¨)", use_sample, 0.1
            )
            if vectorstore_q2:
                st.session_state.vectorstore_q2 = vectorstore_q2
                st.session_state.rag_chain_q2 = create_specialized_rag_chain(vectorstore_q2, "ì¬ë°©ë¬¸ìœ¨")
            
            # Q3 ë°ì´í„° ë¡œë“œ (ìš”ì‹ì—…)
            vectorstore_q3, doc_count_q3 = load_and_index_csv_individual(
                "file/Q3_data.csv", "Q3_data(ìš”ì‹ì—…)", use_sample, 0.1
            )
            if vectorstore_q3:
                st.session_state.vectorstore_q3 = vectorstore_q3
                st.session_state.rag_chain_q3 = create_specialized_rag_chain(vectorstore_q3, "ìš”ì‹ì—…")
            
            if all([vectorstore_q1, vectorstore_q2, vectorstore_q3]):
                st.success(f"âœ… ì „ì²´ ë¡œë”© ì™„ë£Œ!")
                st.success(f"Q1: {doc_count_q1:,}ê°œ | Q2: {doc_count_q2:,}ê°œ | Q3: {doc_count_q3:,}ê°œ")
                st.balloons()
    
    st.markdown("---")
    
    # ë¶„ì„ ëª¨ë“œ ì„ íƒ
    st.markdown("### ğŸ¯ ë¶„ì„ ëª¨ë“œ")
    analysis_mode = st.selectbox(
        "ë¶„ì„ ìœ í˜• ì„ íƒ",
        ["ìë™ ê°ì§€", "ì¹´í˜ì—…ì¢…", "ì¬ë°©ë¬¸ìœ¨", "ìš”ì‹ì—…", "í†µí•©ë¶„ì„"],
        help="ì§ˆë¬¸ì— ë”°ë¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì„ íƒ"
    )
    
    st.markdown("""
    ### ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ
    
    **ğŸµ ì¹´í˜ì—…ì¢…:**
    - "ì„±ìˆ˜ë™ ì¹´í˜ë“¤ì˜ ê³ ê° íŠ¹ì„±ì€?"
    - "ì¶©ì„±ë„ê°€ ë†’ì€ ì¹´í˜ì˜ ê³µí†µì ì€?"
    - "ì—¬ì„± ê³ ê°ì´ ë§ì€ ì¹´í˜ ë§ˆì¼€íŒ… ì „ëµì€?"
    
    **ğŸ”„ ì¬ë°©ë¬¸ìœ¨:**
    - "ì¬ë°©ë¬¸ìœ¨ì´ ë‚®ì€ ë§¤ì¥ ê°œì„  ë°©ì•ˆì€?"
    - "ê³ ê° ì¶©ì„±ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•ì€?"
    - "ë‹¨ê³¨ ê³ ê° í™•ë³´ ì „ëµì€?"
    
    **ğŸ½ï¸ ìš”ì‹ì—…:**
    - "ë°°ë‹¬ ë§¤ì¶œ ë¹„ì¤‘ì´ ë†’ì€ ì—…ì¢…ì€?"
    - "ê°ë‹¨ê°€ ê°œì„  ë°©ì•ˆì€?"
    - "í•œì‹ë‹¹ ê²½ìŸë ¥ ê°•í™” ë°©ë²•ì€?"
    """)

# ë©”ì¸ ì»¨í…ì¸ 
st.title("ğŸª ë§ˆì¼€íŒ… ì „ëµ ë¶„ì„ ì±—ë´‡")
st.markdown("### ğŸ“Š ì¹´í˜ Â· ì¬ë°©ë¬¸ìœ¨ Â· ìš”ì‹ì—… ì „ë¬¸ ë¶„ì„")

# ë°ì´í„° ë¡œë“œ ì²´í¬
if not all([st.session_state.rag_chain_q1, st.session_state.rag_chain_q2, st.session_state.rag_chain_q3]):
    st.warning("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ **'ì „ì²´ ë°ì´í„° ë¡œë“œ'** ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”!")
    st.stop()


# í˜„ì¬ ëª¨ë“œ í‘œì‹œ
st.info(f"ğŸ¯ **í˜„ì¬ ë¶„ì„ ëª¨ë“œ**: {st.session_state.current_mode}")

st.markdown("---")

# ì±„íŒ… ì˜ì—­
st.markdown("### ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")

# ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì±„íŒ… ì…ë ¥
MAX_MESSAGES = 12

if prompt := st.chat_input("ë§ˆì¼€íŒ… ì „ëµì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
    # ë©”ì‹œì§€ ì œí•œ
    if len(st.session_state.messages) >= MAX_MESSAGES:
        del st.session_state.messages[0]
        del st.session_state.messages[0]
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # AI ì‘ë‹µ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # ì§ˆë¬¸ ë¶„ë¥˜ (ìë™ ê°ì§€ ëª¨ë“œì¼ ë•Œ)
            if analysis_mode == "ìë™ ê°ì§€":
                dataset_type, analysis_type = classify_question(prompt)
                st.session_state.current_mode = analysis_type
            else:
                analysis_type = analysis_mode
                if analysis_type == "ì¹´í˜ì—…ì¢…":
                    dataset_type = "Q1"
                elif analysis_type == "ì¬ë°©ë¬¸ìœ¨":
                    dataset_type = "Q2"
                elif analysis_type == "ìš”ì‹ì—…":
                    dataset_type = "Q3"
                else:
                    dataset_type = "í†µí•©"
            
            # í•´ë‹¹í•˜ëŠ” RAG ì²´ì¸ ì„ íƒ
            if dataset_type == "Q1":
                chain = st.session_state.rag_chain_q1
                st.info(f"ğŸµ **ì¹´í˜ì—…ì¢… ë°ì´í„°**ë¡œ ë¶„ì„ ì¤‘...")
            elif dataset_type == "Q2":
                chain = st.session_state.rag_chain_q2
                st.info(f"ğŸ”„ **ì¬ë°©ë¬¸ìœ¨ ë°ì´í„°**ë¡œ ë¶„ì„ ì¤‘...")
            elif dataset_type == "Q3":
                chain = st.session_state.rag_chain_q3
                st.info(f"ğŸ½ï¸ **ìš”ì‹ì—… ë°ì´í„°**ë¡œ ë¶„ì„ ì¤‘...")
            else:
                # í†µí•© ë¶„ì„ - ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²´ì¸ ì‚¬ìš©
                chain = st.session_state.rag_chain_q1  # ê¸°ë³¸ê°’
                st.info(f"ğŸ“Š **í†µí•© ë¶„ì„** ì¤‘...")
            
            # RAG ì‹¤í–‰
            result = chain.invoke({
                "input": prompt,
                "chat_history": st.session_state.messages
            })
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            answer_text = result.get("answer", "")
            
            # ì‘ë‹µ ì™„ì „ì„± ê²€ì¦
            is_complete = (
                len(answer_text) > 100 and  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                (answer_text.endswith(('.', '!', '?', 'ë‹¤', 'ìš”', 'ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ì„¸ìš”')) or
                 "ë§ˆë¬´ë¦¬" in answer_text or
                 "ìš”ì•½" in answer_text)
            )
            
            if not is_complete and len(answer_text) > 50:
                st.warning("âš ï¸ ì‘ë‹µì´ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
            # ì°¸ê³  ë°ì´í„° í‘œì‹œ
            with st.expander("ğŸ“š ì°¸ê³  ë°ì´í„°"):
                for i, doc in enumerate(result["context"], 1):
                    st.markdown(f"**ë°ì´í„° {i}:**")
                    st.text(doc.page_content[:400])
                    st.markdown("---")
            
            # íƒ€ì´í•‘ íš¨ê³¼ë¡œ ì‘ë‹µ í‘œì‹œ
            for chunk in answer_text.split(" "):
                full_response += chunk + " "
                time.sleep(0.05)
                message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
            # ë©”ì‹œì§€ ì €ì¥
            st.session_state.messages.append(
                {"role": "assistant", "content": full_response}
            )
        
        except Exception as e:
            error_message = f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.error(error_message)
            st.session_state.messages.append(
                {"role": "assistant", "content": error_message}
            )

# í‘¸í„°
st.markdown("---")
st.caption("ğŸ’¡ Tip: ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì ì ˆí•œ ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")
